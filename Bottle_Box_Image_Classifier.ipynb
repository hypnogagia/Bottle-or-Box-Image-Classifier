{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Is it a bottle?","metadata":{}},{"cell_type":"markdown","source":"\nThe basic steps we'll take are:\n\n1. Use DuckDuckGo to search for images of \"bottle photos\"\n1. Use DuckDuckGo to search for images of \" photos\"\n1. Fine-tune a pretrained neural network to recognise these two groups\n1. Try running this model on a picture of a bird and see if it works.","metadata":{}},{"cell_type":"markdown","source":"## Step 1: Download images of bottle and non-bottle","metadata":{}},{"cell_type":"code","source":"from duckduckgo_search import ddg_images\nfrom fastcore.all import *\n\ndef search_images(term, max_images=30):\n    print(f\"Searching for '{term}'\")\n    return L(ddg_images(term, max_results=max_images)).itemgot('image')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-02-12T16:22:57.803907Z","iopub.execute_input":"2023-02-12T16:22:57.804206Z","iopub.status.idle":"2023-02-12T16:22:57.838813Z","shell.execute_reply.started":"2023-02-12T16:22:57.804142Z","shell.execute_reply":"2023-02-12T16:22:57.838114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's start by searching for a bottle photo and seeing what kind of result we get. We'll start by getting URLs from a search:","metadata":{}},{"cell_type":"code","source":"#NB: `search_images` depends on duckduckgo.com, which doesn't always return correct responses.\n#    If you get a JSON error, just try running it again (it may take a couple of tries).\nurls = search_images('bottle photos', max_images=1)\nurls[0]","metadata":{"execution":{"iopub.status.busy":"2023-02-12T16:22:57.840876Z","iopub.execute_input":"2023-02-12T16:22:57.84115Z","iopub.status.idle":"2023-02-12T16:22:58.689696Z","shell.execute_reply.started":"2023-02-12T16:22:57.841113Z","shell.execute_reply":"2023-02-12T16:22:58.688986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"...and then download a URL and take a look at it:","metadata":{}},{"cell_type":"code","source":"from fastdownload import download_url\ndest = 'bottle.jpg'\ndownload_url(urls[0], dest, show_progress=False)\n\nfrom fastai.vision.all import *\nim = Image.open(dest)\nim.to_thumb(256,256)","metadata":{"execution":{"iopub.status.busy":"2023-02-12T16:22:58.690782Z","iopub.execute_input":"2023-02-12T16:22:58.691158Z","iopub.status.idle":"2023-02-12T16:23:01.767939Z","shell.execute_reply.started":"2023-02-12T16:22:58.691123Z","shell.execute_reply":"2023-02-12T16:23:01.767238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let's do the same with \"box photos\":","metadata":{}},{"cell_type":"code","source":"download_url(search_images('box photos', max_images=1)[0], 'box.jpg', show_progress=False)\nImage.open('box.jpg').to_thumb(256,256)","metadata":{"execution":{"iopub.status.busy":"2023-02-12T16:23:38.438376Z","iopub.execute_input":"2023-02-12T16:23:38.43865Z","iopub.status.idle":"2023-02-12T16:23:39.327824Z","shell.execute_reply.started":"2023-02-12T16:23:38.43862Z","shell.execute_reply":"2023-02-12T16:23:39.327191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our searches seem to be giving reasonable results, so let's grab a few examples of each of \"bottle\" and \"box\" photos, and save each group of photos to a different folder (I'm also trying to grab a range of conditions here):","metadata":{}},{"cell_type":"code","source":"searches = 'box','bottle'\npath = Path('bottle_or_not')\nfrom time import sleep\n\nfor o in searches:\n    dest = (path/o)\n    dest.mkdir(exist_ok=True, parents=True)\n    download_images(dest, urls=search_images(f'{o} photo'))\n    sleep(10)  # Pause between searches to avoid over-loading server\n    download_images(dest, urls=search_images(f'{o} open photo'))\n    sleep(10)\n    download_images(dest, urls=search_images(f'{o} closed photo'))\n    sleep(10)\n    resize_images(path/o, max_size=400, dest=path/o)","metadata":{"execution":{"iopub.status.busy":"2023-02-12T16:25:28.882407Z","iopub.execute_input":"2023-02-12T16:25:28.882706Z","iopub.status.idle":"2023-02-12T16:27:02.453147Z","shell.execute_reply.started":"2023-02-12T16:25:28.882677Z","shell.execute_reply":"2023-02-12T16:27:02.45225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 2: Train our model","metadata":{}},{"cell_type":"markdown","source":"Some photos might not download correctly which could cause our model training to fail, so we'll remove them:","metadata":{}},{"cell_type":"code","source":"failed = verify_images(get_image_files(path))\nfailed.map(Path.unlink)\nlen(failed)","metadata":{"execution":{"iopub.status.busy":"2023-02-12T16:27:09.095043Z","iopub.execute_input":"2023-02-12T16:27:09.095828Z","iopub.status.idle":"2023-02-12T16:27:09.796682Z","shell.execute_reply.started":"2023-02-12T16:27:09.095788Z","shell.execute_reply":"2023-02-12T16:27:09.795932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To train a model, we'll need `DataLoaders`, which is an object that contains a *training set* (the images used to create a model) and a *validation set* (the images used to check the accuracy of a model -- not used during training). In `fastai` we can create that easily using a `DataBlock`, and view sample images from it:","metadata":{}},{"cell_type":"code","source":"dls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=[Resize(192, method='squish')]\n).dataloaders(path, bs=32)\n\ndls.show_batch(max_n=6)","metadata":{"execution":{"iopub.status.busy":"2023-02-12T16:27:25.614265Z","iopub.execute_input":"2023-02-12T16:27:25.61456Z","iopub.status.idle":"2023-02-12T16:27:29.574663Z","shell.execute_reply.started":"2023-02-12T16:27:25.614529Z","shell.execute_reply":"2023-02-12T16:27:29.573944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here what each of the `DataBlock` parameters means:\n\n    blocks=(ImageBlock, CategoryBlock),\n\nThe inputs to our model are images, and the outputs are categories (in this case, \"bird\" or \"forest\").\n\n    get_items=get_image_files, \n\nTo find all the inputs to our model, run the `get_image_files` function (which returns a list of all image files in a path).\n\n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n\nSplit the data into training and validation sets randomly, using 20% of the data for the validation set.\n\n    get_y=parent_label,\n\nThe labels (`y` values) is the name of the `parent` of each file (i.e. the name of the folder they're in, which will be *bird* or *forest*).\n\n    item_tfms=[Resize(192, method='squish')]\n\nBefore training, resize each image to 192x192 pixels by \"squishing\" it (as opposed to cropping it).","metadata":{}},{"cell_type":"markdown","source":"Now we're ready to train our model. The fastest widely used computer vision model is `resnet18`. You can train this in a few minutes, even on a CPU! (On a GPU, it generally takes under 10 seconds...)\n\n`fastai` comes with a helpful `fine_tune()` method which automatically uses best practices for fine tuning a pre-trained model, so we'll use that.","metadata":{}},{"cell_type":"code","source":"learn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(3)","metadata":{"execution":{"iopub.status.busy":"2023-02-12T16:27:45.149194Z","iopub.execute_input":"2023-02-12T16:27:45.149962Z","iopub.status.idle":"2023-02-12T16:28:05.145658Z","shell.execute_reply.started":"2023-02-12T16:27:45.149924Z","shell.execute_reply":"2023-02-12T16:28:05.14476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 3: Use our model","metadata":{}},{"cell_type":"markdown","source":"Let's see what our model thinks about that bottle we downloaded at the start:","metadata":{}},{"cell_type":"code","source":"is_bottle,_,probs = learn.predict(PILImage.create('bottle.jpg'))\nprint(f\"This is a: {is_bottle}.\")\nprint(f\"Probability it's a bottle: {probs[0]:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2023-02-12T16:28:30.828716Z","iopub.execute_input":"2023-02-12T16:28:30.829013Z","iopub.status.idle":"2023-02-12T16:28:30.91002Z","shell.execute_reply.started":"2023-02-12T16:28:30.828977Z","shell.execute_reply":"2023-02-12T16:28:30.909184Z"},"trusted":true},"execution_count":null,"outputs":[]}]}